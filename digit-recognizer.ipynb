{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Digit Recognizer Challenge solved with tensorflow CNN's**","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom tensorflow.keras import layers as ly\nimport os\n\ntf.random.set_seed(10)\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-30T16:17:27.217750Z","iopub.execute_input":"2023-10-30T16:17:27.218188Z","iopub.status.idle":"2023-10-30T16:17:34.331319Z","shell.execute_reply.started":"2023-10-30T16:17:27.218152Z","shell.execute_reply":"2023-10-30T16:17:34.330276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n### Train Dataframe Overview: ","metadata":{}},{"cell_type":"code","source":"traindf = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\nprint(f'Dataframe shape: {traindf.shape}\\nMin/Max Values: {np.min(traindf.values)} - {np.max(traindf.values)}\\nLabels:{traindf.sort_values(\"label\").label.unique()}\\n')\n\nprint('Number of samples for each label:')\nsample_count = traindf.groupby('label').count()['pixel0'].to_dict()\nfor i in sample_count:\n    print(f'  Label {i} - {sample_count[i]}')\n\nprint(f'\\nDataframe head:')\ntraindf.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-30T16:17:34.333067Z","iopub.execute_input":"2023-10-30T16:17:34.334160Z","iopub.status.idle":"2023-10-30T16:17:38.156120Z","shell.execute_reply.started":"2023-10-30T16:17:34.334122Z","shell.execute_reply":"2023-10-30T16:17:38.155127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n### Dataframe overview for test.csv who will used for submission results:","metadata":{}},{"cell_type":"code","source":"subdf = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\nprint(f'Dataframe shape: {subdf.shape}\\nMin/Max Values: {np.min(subdf.values)} - {np.max(subdf.values)}\\n\\nDataframe head:')\n    \nsubdf.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-30T16:17:38.157654Z","iopub.execute_input":"2023-10-30T16:17:38.157948Z","iopub.status.idle":"2023-10-30T16:17:40.304536Z","shell.execute_reply.started":"2023-10-30T16:17:38.157922Z","shell.execute_reply":"2023-10-30T16:17:40.303417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nn = 5\nprint(f'Showing the {n} first images of train dataframe.')\n\nfor i in range(n):\n    plt.title(f'Label: {traindf.iloc[i,0]}')\n    plt.imshow( traindf.iloc[i, 1:].values.reshape(28,28), cmap='Greys' )\n    plt.axis('off')\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-30T16:17:40.306594Z","iopub.execute_input":"2023-10-30T16:17:40.306938Z","iopub.status.idle":"2023-10-30T16:17:41.125678Z","shell.execute_reply.started":"2023-10-30T16:17:40.306913Z","shell.execute_reply":"2023-10-30T16:17:41.124991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we are expecting a highly efficient model in recognizing these numbers, we will need to consider a prediction of the rotated numbers.\n\n**Data Augmentation**, is a process that we change several characteristics of the images in order to increase the input data for each label to be predicted and consequently giving more inputs to the computational model we are training.\n\nFor this data augmentation process, we will use the ImageDataGenerator and together with flow_from_directory will be necessary to convert our data to images organized in class subdirectories, as this is how these methods work.\n\nIn the code below we extract, separate the training and validation sets, retrieve the ocurrence of unique labels, create the folders and fill them with the image files with ther index name on each training and validation paths.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndataset = pd.DataFrame({'path':traindf.index, 'label':traindf.label})\nxtrain, xtest, ytrain, ytest = train_test_split(traindf.iloc[:,1:], traindf.label, test_size=0.2)\n\ntrain_classes = [str(lbl) for lbl in ytrain.unique()]\ntrain_classes.sort()\n\ntest_classes = [str(lbl) for lbl in ytest.unique()]\ntest_classes.sort()\n\nfor item in [ ('images_for_training', xtrain, ytrain), ('images_for_test', xtest, ytest) ]:\n    \n    label_paths = [ str(lbl) for lbl in item[2].unique() ]\n    \n    for path in label_paths:\n        os.makedirs(f'./{item[0]}/{path}', exist_ok=True)    \n\n    for idx,row in item[1].iterrows():\n        img = row.values.reshape(28,28)\n        plt.imsave(arr= img, fname= f'./{ item[0] }/{ item[2][idx] }/{ idx }.png', cmap= 'gray')\n    ","metadata":{"execution":{"iopub.status.busy":"2023-10-30T16:17:41.126756Z","iopub.execute_input":"2023-10-30T16:17:41.127568Z","iopub.status.idle":"2023-10-30T16:18:52.463663Z","shell.execute_reply.started":"2023-10-30T16:17:41.127538Z","shell.execute_reply":"2023-10-30T16:18:52.462818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    rescale=1/255,\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2\n)\n\ntrain_data = datagen.flow_from_directory(\n    directory='/kaggle/working/images_for_training/',\n    target_size=(28,28),\n    color_mode=\"grayscale\",\n    class_mode=\"categorical\",\n    classes=train_classes,\n    batch_size=32\n)\n\ntest_data = datagen.flow_from_directory(\n    directory='/kaggle/working/images_for_test/',\n    target_size=(28,28),\n    color_mode=\"grayscale\",\n    class_mode=\"categorical\",\n    classes=test_classes,\n    batch_size=32\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T16:18:52.465059Z","iopub.execute_input":"2023-10-30T16:18:52.465809Z","iopub.status.idle":"2023-10-30T16:18:53.825961Z","shell.execute_reply.started":"2023-10-30T16:18:52.465771Z","shell.execute_reply":"2023-10-30T16:18:53.825171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is a just simple and quick test for checking data_generator and flow_from_directory\n\nimport random\n\nimg, txt = test_data.next()\ni = random.randint(0,31)\nplt.axis('off')\nprint(f'{ txt[i] } -> label = { np.argmax(txt[i]) }')\nplt.imshow(img[i], cmap='Greys')","metadata":{"execution":{"iopub.status.busy":"2023-10-30T16:18:53.827013Z","iopub.execute_input":"2023-10-30T16:18:53.827315Z","iopub.status.idle":"2023-10-30T16:18:53.938663Z","shell.execute_reply.started":"2023-10-30T16:18:53.827289Z","shell.execute_reply":"2023-10-30T16:18:53.937478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining some util objects for our context\n\ndef plot_loss_curves(history):\n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  accuracy = history.history['accuracy']\n  val_accuracy = history.history['val_accuracy']\n\n  epochs = range(len(history.history['loss']))\n\n  # Plot loss\n  plt.figure(figsize=(20,4))  \n  plt.plot(epochs, loss, label='training_loss')\n  plt.plot(epochs, val_loss, label='val_loss')\n  plt.title('Loss')\n  plt.xlabel('Epochs')\n  plt.legend()\n\n  # Plot accuracy\n  plt.figure(figsize=(20,4))\n  plt.plot(epochs, accuracy, label='training_accuracy')\n  plt.plot(epochs, val_accuracy, label='val_accuracy')\n  plt.title('Accuracy')\n  plt.xlabel('Epochs')\n  plt.legend();\n\n    \nclass MyCheckPoint(tf.keras.callbacks.ModelCheckpoint):\n    \n    def __init__(self, name):\n        if not os.path.exists('model_checkpoint'): \n            os.makedirs('model_checkpoint')\n        else:\n            if not os.path.exists(f'model_checkpoint/{name}'):\n                os.makedirs(f'./model_checkpoint/{name}')\n\n        super().__init__(\n            f'./model_checkpoint/{name}',\n            save_weights_only=True,\n            monitor='val_accuracy',\n            mode='max',\n            save_best_only=True)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-10-30T16:18:53.940079Z","iopub.execute_input":"2023-10-30T16:18:53.942389Z","iopub.status.idle":"2023-10-30T16:18:53.958192Z","shell.execute_reply.started":"2023-10-30T16:18:53.942338Z","shell.execute_reply":"2023-10-30T16:18:53.956857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Constructing our models","metadata":{}},{"cell_type":"code","source":"model_3 = tf.keras.models.Sequential([\n    ly.InputLayer(input_shape=(28,28,1)),\n    ly.Conv2D(filters=32, kernel_size=2, strides=1, activation='relu'),\n    ly.Conv2D(28,2, activation='relu'),\n    ly.MaxPool2D(),\n    ly.Conv2D(24,2, activation='relu'),\n    ly.MaxPool2D(),\n    ly.Flatten(),\n    ly.Dense(10, activation='softmax')\n])\n\nmodel_3.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_3.compile(loss= tf.keras.losses.categorical_crossentropy,\n               optimizer=tf.keras.optimizers.Adam(),\n               metrics=['accuracy'])\n\ntraining_model_3 = model_3.fit(train_data,\n                              epochs=12, steps_per_epoch=len(train_data),\n                              validation_data=test_data,\n                              validation_steps=len(test_data),\n                              callbacks=[ MyCheckPoint('model_3') ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(training_model_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing our model with prediction samples","metadata":{}},{"cell_type":"code","source":"# Random choice on index submission\nrand_idx = random.choices(subdf.index)[0]\n\n# Get sample of this random index\nsample = subdf.iloc[rand_idx].values.reshape(28,28)\n\n# Sample prediction\npreds = model_3.predict( tf.expand_dims( sample/255, axis=0 ), verbose=0 )\n\n# Results\nprint( f'\\n Model Prediction is {np.argmax(preds)} \\n' )\nplt.imshow(sample, cmap='Greys')\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating submission file","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef create_submission_file(model, name=''):\n    submission = pd.DataFrame()\n    progress_bar = tqdm(total=subdf.shape[0])\n\n    for idx,row in subdf.iterrows():\n        image = tf.expand_dims(row.values.reshape(28,28)/255, axis=0)\n        prediction = pd.DataFrame( [np.argmax(model.predict(image, verbose=0))],  columns=['Label'], index=[idx+1])\n        submission = pd.concat([submission, prediction], axis=0)\n        progress_bar.update(1)\n\n    submission.index.name = 'ImageId'\n    submission.to_csv(f'submission_{name}.csv')\n\n#create_submission_file(model_3, '001') - position 1228 - score 0.96392","metadata":{"execution":{"iopub.status.busy":"2023-10-30T17:47:02.365548Z","iopub.execute_input":"2023-10-30T17:47:02.366170Z","iopub.status.idle":"2023-10-30T17:47:02.379285Z","shell.execute_reply.started":"2023-10-30T17:47:02.366142Z","shell.execute_reply":"2023-10-30T17:47:02.378154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Improving model","metadata":{}},{"cell_type":"code","source":"model_4 = tf.keras.models.Sequential([\n    ly.InputLayer(input_shape=(28,28,1)),\n    ly.Dense(64, activation='relu'),\n    ly.Conv2D(filters=32, kernel_size=2, strides=1, activation='relu'),\n    ly.Conv2D(32,2, activation='relu'),\n    ly.MaxPool2D(),\n    ly.Dense(32, activation='relu'),\n    ly.Conv2D(32,2, activation='relu'),\n    ly.AvgPool2D(),\n    ly.Flatten(),\n    ly.Dense(10, activation='softmax')\n])\n\nmodel_4.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-30T16:45:31.110616Z","iopub.execute_input":"2023-10-30T16:45:31.111472Z","iopub.status.idle":"2023-10-30T16:45:31.249949Z","shell.execute_reply.started":"2023-10-30T16:45:31.111435Z","shell.execute_reply":"2023-10-30T16:45:31.248851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_4.compile(loss= tf.keras.losses.categorical_crossentropy,\n               optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n               metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-10-30T16:46:00.696091Z","iopub.execute_input":"2023-10-30T16:46:00.696966Z","iopub.status.idle":"2023-10-30T16:46:00.708607Z","shell.execute_reply.started":"2023-10-30T16:46:00.696929Z","shell.execute_reply":"2023-10-30T16:46:00.707555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import EarlyStopping\n\ntraining_model_4 = model_4.fit(train_data,\n                              epochs=50, steps_per_epoch=len(train_data),\n                              validation_data=test_data,\n                              validation_steps=len(test_data),\n                              callbacks=[ MyCheckPoint('model_4'),\n                                        ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.33, verbose=1),\n                                        EarlyStopping(monitor='va_loss', patience=2, restore_best_weights=True, start_from_epoch=30)])","metadata":{"execution":{"iopub.status.busy":"2023-10-30T16:47:04.347695Z","iopub.execute_input":"2023-10-30T16:47:04.348572Z","iopub.status.idle":"2023-10-30T17:12:44.497346Z","shell.execute_reply.started":"2023-10-30T16:47:04.348536Z","shell.execute_reply":"2023-10-30T17:12:44.496493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(training_model_4)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T17:41:04.676179Z","iopub.execute_input":"2023-10-30T17:41:04.676944Z","iopub.status.idle":"2023-10-30T17:41:05.269463Z","shell.execute_reply.started":"2023-10-30T17:41:04.676911Z","shell.execute_reply":"2023-10-30T17:41:05.268475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_submission_file(model_4, '002')","metadata":{"execution":{"iopub.status.busy":"2023-10-30T17:47:09.030815Z","iopub.execute_input":"2023-10-30T17:47:09.031192Z","iopub.status.idle":"2023-10-30T18:13:10.823943Z","shell.execute_reply.started":"2023-10-30T17:47:09.031165Z","shell.execute_reply":"2023-10-30T18:13:10.822918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This last model_4 reach out 0.98417 score and 805 position on leaderboard at 30/10/2023","metadata":{}}]}