{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/xslyr/LbEncoder/main/lbencoder.py\n!pip install pycaret","metadata":{"execution":{"iopub.status.busy":"2023-11-09T19:49:28.210629Z","iopub.execute_input":"2023-11-09T19:49:28.211010Z","iopub.status.idle":"2023-11-09T19:50:11.104334Z","shell.execute_reply.started":"2023-11-09T19:49:28.210978Z","shell.execute_reply":"2023-11-09T19:50:11.102967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport lbencoder, warnings\nfrom enum import Enum\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_squared_log_error\nfrom sklearn.model_selection import train_test_split\n\nfrom pycaret.regression import setup, compare_models, tune_model\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers as ly\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.utils import plot_model\n\nwarnings.filterwarnings('ignore')\ntf.random.set_seed(10)\n\nEXEC_MODE = 'test'\nFEAT_SELECT = 0.5\nQTY_REGRESSORS = 10\nTUNE_REGRESSORS = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-09T19:50:11.107057Z","iopub.execute_input":"2023-11-09T19:50:11.107455Z","iopub.status.idle":"2023-11-09T19:50:24.817131Z","shell.execute_reply.started":"2023-11-09T19:50:11.107419Z","shell.execute_reply":"2023-11-09T19:50:24.815910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Loading input data**","metadata":{}},{"cell_type":"code","source":"# Loading xtrain datraframe\ntrain = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntrain_id = train['Id']\ntrain['MSSubClass'] = train['MSSubClass'].astype(str)\n\n# Loading xtest dataframe\ntest = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\ntest_id = test['Id']\ntest['MSSubClass'] = test['MSSubClass'].astype(str)\n\n# Merging x_train and x_test. \n# This is convenient for us to prepare data just one time instead do it separately in x_test. \n# The right way is to build a pipeline of methods that will do this transformations for us.\ndataframe = pd.concat([train,test], axis=0)\ndataframe.index = list(dataframe['Id'])\n\ny_train = dataframe.iloc[:list(train_id)[-1],-1]\ndataframe = dataframe.drop(['Id', 'SalePrice'], axis=1) \n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T19:50:24.818665Z","iopub.execute_input":"2023-11-09T19:50:24.819444Z","iopub.status.idle":"2023-11-09T19:50:24.916095Z","shell.execute_reply.started":"2023-11-09T19:50:24.819404Z","shell.execute_reply":"2023-11-09T19:50:24.914959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Miss values treatment**\nSome columns adopt the string 'None' or 'NA' to mention nan values. Right below we ensure this occurrence properly.\nFor object columns, we fill nan values based on K-Neighbors Classification proximity., in the same way, K-Neighbors Regression to change nan values by numbers.","metadata":{}},{"cell_type":"code","source":"fill_None = ['MasVnrType']\nfill_NA = ['Alley','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu',\n           'GarageType','GarageFinish','GarageQual','GarageCond','PoolQC','Fence','MiscFeature']\n\nfor col in fill_NA:\n    dataframe[col] = dataframe[col].fillna('NA')\n    \nfor col in fill_None:\n    dataframe[col] = dataframe[col].fillna('None')\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-09T19:50:24.917594Z","iopub.execute_input":"2023-11-09T19:50:24.917967Z","iopub.status.idle":"2023-11-09T19:50:24.937337Z","shell.execute_reply.started":"2023-11-09T19:50:24.917935Z","shell.execute_reply":"2023-11-09T19:50:24.935666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_nulls(strtype):\n    if strtype=='all':\n        return pd.DataFrame(dataframe.isna().sum(), columns=['sum'])\n    else:\n        param = object if strtype=='object' else np.number\n        na = pd.DataFrame(dataframe.select_dtypes(param).isna().sum(), columns=['sum'])\n        return na.loc[na['sum']>0].sort_values('sum', ascending=False)\n    \ndef knc_imputer(df, target):\n    numdf = dataframe.select_dtypes(np.number)\n    columns = numdf.loc[:, numdf.notna().all() ].columns\n    x_train = df.loc[ df[target].notna(), columns ]\n    y_train = df.loc[ df[target].notna(), target ]\n    x_test = df.loc[ df[target ].isna(), columns ]\n    knn = KNeighborsClassifier()\n    knn.fit(x_train,y_train)\n    return knn.predict(x_test)\n\nfor item in get_nulls('object').index:\n    dataframe.loc[dataframe[item].isna()==True, item] = knc_imputer(dataframe, item)\n  ","metadata":{"execution":{"iopub.status.busy":"2023-11-09T19:50:24.941253Z","iopub.execute_input":"2023-11-09T19:50:24.942092Z","iopub.status.idle":"2023-11-09T19:50:25.201078Z","shell.execute_reply.started":"2023-11-09T19:50:24.942045Z","shell.execute_reply":"2023-11-09T19:50:25.199611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def knr_imputer(df, target):\n    numdf = df.select_dtypes(np.number)\n    columns = numdf.loc[:, numdf.notna().all() ].columns\n\n    first_inertia, n_clusters = 0,1\n    for i in range(1, 15):\n        kmeans = KMeans(n_clusters = i, init = 'k-means++', n_init='auto', random_state = 0)\n        kmeans.fit(df[columns])\n        if i==1 : first_inertia = kmeans.inertia_\n        else:\n            if kmeans.inertia_/first_inertia < 0.03: break\n            else: n_clusters=i\n            \n    x_train = df.loc[ df[target].notna(), columns ]\n    y_train = df.loc[ df[target].notna(), target ]\n    x_test = df.loc[ df[target ].isna(), columns ]\n    knr = KNeighborsRegressor(n_neighbors=n_clusters, weights='distance',algorithm='auto')\n    knr.fit(x_train,y_train)\n    return knr.predict(x_test)\n\nfor item in get_nulls('number').index:\n    dataframe.loc[dataframe[item].isna()==True, item] = knr_imputer(dataframe, item)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T01:33:14.254923Z","iopub.execute_input":"2023-11-15T01:33:14.255317Z","iopub.status.idle":"2023-11-15T01:33:14.294668Z","shell.execute_reply.started":"2023-11-15T01:33:14.255285Z","shell.execute_reply":"2023-11-15T01:33:14.293459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Feature Engineering**\nML models read numbers, so we need find ways to transform categorical features on something readable by this machines.\nBelow I used some wonderful tactic for some columns. It's consist in change each value by statistical occurrences on their \"feature space\".\n","metadata":{}},{"cell_type":"code","source":"def get_dictionary(target, addcols=['mean','median'], log_target=False):\n    # range e sum foram retirados das colunas padrões pois são influenciados pela quantidade de registros\n    \n    aux_df = train[[target,'SalePrice']].copy()\n    if log_target: aux_df['SalePrice'] = np.log2(aux_df['SalePrice'])\n    dictionary_cols = []\n    if 'mean' in addcols: dictionary_cols.append('{}.mean'.format(target))\n    if 'median' in addcols: dictionary_cols.append('{}.median'.format(target))\n    line = []\n    if 'mean' in addcols: line.append(aux_df['SalePrice'].mean())\n    if 'median' in addcols: line.append(aux_df['SalePrice'].median())\n    dictionary_df = pd.DataFrame([line], index=['AllData'], columns=dictionary_cols)\n    for item in aux_df[target].unique():\n        ocurrence = aux_df.loc[ aux_df[target]== item ]\n        line = []\n        if 'mean' in addcols: line.append(ocurrence['SalePrice'].mean())\n        if 'median' in addcols: line.append(ocurrence['SalePrice'].median())\n        dictionary_df = pd.concat( [dictionary_df, pd.DataFrame([line], index=[item], columns=dictionary_cols)], axis=0)\n    dictionary_df = dictionary_df.fillna(0)\n    return dictionary_df\n\ndef change_columns_to_details(dataframe, column ,dictionary):\n    aux_df, data = pd.DataFrame(), dataframe.copy()\n    for line in data[column]:\n        try: aux_df = pd.concat( [aux_df, pd.DataFrame(dictionary.loc[line]).transpose() ], axis=0)\n        except: aux_df = pd.concat( [aux_df, pd.DataFrame(dictionary.loc['AllData']).transpose() ], axis=0)\n        \n    aux_df.index = data.index\n    index_2b_change = data.columns.get_loc(column)\n    return pd.concat([data.iloc[:,:index_2b_change], aux_df ,data.iloc[:,index_2b_change+1:]], axis=1)\n\n  \nfor col in ['Neighborhood','MSSubClass','MSZoning','HouseStyle','BldgType','LotShape','Condition1','Condition2','Electrical','Exterior1st','Exterior2nd','Foundation','Functional','LotConfig','RoofStyle']:\n    dataframe = change_columns_to_details(dataframe, col, get_dictionary(col))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T19:50:45.661709Z","iopub.execute_input":"2023-11-09T19:50:45.662563Z","iopub.status.idle":"2023-11-09T19:51:22.520545Z","shell.execute_reply.started":"2023-11-09T19:50:45.662521Z","shell.execute_reply":"2023-11-09T19:51:22.519179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe['AverageRoomSize'] = dataframe['GrLivArea']/(dataframe['TotRmsAbvGrd']+ dataframe['FullBath']+ dataframe['HalfBath']+ dataframe['BsmtFullBath'] + dataframe['BsmtHalfBath'] )\ndataframe['QualityOverview'] = dataframe['OverallCond'] + dataframe['OverallQual']\n\ndataframe['MoSold'] = dataframe['MoSold'].apply(lambda x:-np.cos(0.5236*x)+1)\n\ndataframe['YrBetweenBuiltSold'] = dataframe['YrSold']-dataframe['YearBuilt']+dataframe['MoSold']/12\ndataframe['YrBetweenBuiltSold'] = dataframe['YrBetweenBuiltSold'].apply(lambda x: 0 if x < 0 else x)\n\ndataframe['YrBetweenRemodSold'] = dataframe['YrSold'] - dataframe['YearRemodAdd'] + dataframe['MoSold']/12\ndataframe['YrBetweenRemodSold'] = dataframe['YrBetweenRemodSold'].apply(lambda x: 0 if x < 0 else x)\n\n\nScalerColumns = { \n    'ExterQual': ['Po','Fa','TA','Gd','Ex'],\n    'ExterCond': ['Po','Fa','TA','Gd','Ex'],\n    'BsmtQual': ['NA','Po','Fa','TA','Gd','Ex'],\n    'BsmtCond': ['NA','Po','Fa','TA','Gd','Ex'],\n    'BsmtExposure': ['NA','No','Mn','Av','Gd'],\n    'BsmtFinType1': ['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],\n    'BsmtFinType2': ['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],\n    'HeatingQC' : ['Po','Fa','TA','Gd','Ex'],\n    'KitchenQual' : ['NA','Fa','TA','Gd','Ex'],\n    'FireplaceQu' : ['NA','Po','Fa','TA','Gd','Ex'],\n    'GarageFinish': ['NA','Unf','RFn','Fin'],\n    'GarageQual' : ['NA','Po','Fa','TA','Gd','Ex'],\n    'GarageCond' : ['NA','Po','Fa','TA','Gd','Ex'],\n    'PoolQC': ['NA','Fa','TA','Gd','Ex'],\n    'Alley': ['NA','Grvl','Pave']\n}\nsc_scalers = {}\n\nfor col in ScalerColumns:\n    sc_scalers[col] = lbencoder.LbEncoder()\n    dataframe[col] = sc_scalers[col].fit_transform(dataframe[col], sort_by=ScalerColumns[col])\n\n\ndataframe['OpenScreen3SsnPorchSF'] = dataframe['OpenPorchSF']+dataframe['3SsnPorch']+dataframe['ScreenPorch']\ndataframe['GeneralExternEvaluation'] = dataframe['ExterQual'] + dataframe['ExterCond']\ndataframe['BsmtFinTypes'] = dataframe['BsmtFinType1'] + dataframe['BsmtFinType2']\ndataframe['BsmtFinSFs'] = dataframe['BsmtFinSF1']+dataframe['BsmtFinSF2']\ndataframe['BsmtBaths'] = dataframe['BsmtFullBath'] + 0.5*dataframe['BsmtHalfBath']\ndataframe['LowQualFinSF'] = dataframe['LowQualFinSF']/( dataframe['GrLivArea'] + dataframe['TotalBsmtSF'] )\ndataframe['BathsAboveGrade'] = dataframe['FullBath'] + 0.5*dataframe['HalfBath']\n\n\ndataframe = pd.get_dummies(dataframe, columns=['MiscFeature'])\ndataframe['GarageCond'] = dataframe['GarageCond']+ dataframe['MiscVal']*dataframe['MiscFeature_Gar2']/dataframe['MiscVal'].max()\ndataframe['MiscFeature_Othr'] = dataframe['MiscVal']*dataframe['MiscFeature_Othr']/dataframe['MiscVal'].max()\ndataframe['MiscFeature_Shed'] = dataframe['MiscVal']*dataframe['MiscFeature_Shed']/dataframe['MiscVal'].max()\ndataframe['MiscFeature_TenC'] = dataframe['MiscVal']*dataframe['MiscFeature_TenC']/dataframe['MiscVal'].max()\n\n\ndataframe = dataframe.drop(['MiscVal','MiscFeature_Gar2'], axis=1)\ndataframe = dataframe.drop(['OpenPorchSF','3SsnPorch','ScreenPorch'], axis=1)\ndataframe = dataframe.drop(['ExterQual','ExterCond'], axis=1)\ndataframe = dataframe.drop(['FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath'], axis=1)\ndataframe = dataframe.drop(['YrSold','MoSold'], axis=1)\ndataframe = dataframe.drop(['BsmtFinType1','BsmtFinType2'], axis=1)\ndataframe = dataframe.drop(['BsmtFinSF1','BsmtFinSF2'], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T19:51:22.522065Z","iopub.execute_input":"2023-11-09T19:51:22.522434Z","iopub.status.idle":"2023-11-09T19:51:22.616411Z","shell.execute_reply.started":"2023-11-09T19:51:22.522402Z","shell.execute_reply":"2023-11-09T19:51:22.615146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Column Encoding and Feature Scaling**","metadata":{}},{"cell_type":"code","source":"stde = StandardScaler()\n\ndata_dummie = pd.get_dummies(dataframe)\ndata_dummie = pd.DataFrame(stde.fit_transform(data_dummie), columns=data_dummie.columns, index=data_dummie.index)\nx_train = data_dummie.iloc[:1460,:]\nx_test = data_dummie.iloc[1460:,:]\n\nxtrain, xval, ytrain, yval = train_test_split(x_train, y_train, test_size=0.2)\n\nprint(f'Shape of train dataframe: {xtrain.shape}\\nShape of test dataframe: {xval.shape}')","metadata":{"execution":{"iopub.status.busy":"2023-11-09T19:51:22.617921Z","iopub.execute_input":"2023-11-09T19:51:22.618356Z","iopub.status.idle":"2023-11-09T19:51:22.664613Z","shell.execute_reply.started":"2023-11-09T19:51:22.618321Z","shell.execute_reply":"2023-11-09T19:51:22.663459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-----------","metadata":{}},{"cell_type":"markdown","source":"# **Model Selection**","metadata":{}},{"cell_type":"code","source":"if EXEC_MODE == 'main':\n    _ = setup(data = pd.concat([x_train,y_train],axis=1), target='SalePrice', feature_selection=True, n_features_to_select=FEAT_SELECT, verbose=1) \nelse:\n    _ = setup(data = pd.concat([xtrain,ytrain],axis=1), target='SalePrice', feature_selection=True, n_features_to_select=FEAT_SELECT, verbose=1) \n    \nmodels_set = compare_models(n_select=QTY_REGRESSORS)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T19:51:22.665877Z","iopub.execute_input":"2023-11-09T19:51:22.666240Z","iopub.status.idle":"2023-11-09T19:55:31.282547Z","shell.execute_reply.started":"2023-11-09T19:51:22.666208Z","shell.execute_reply":"2023-11-09T19:55:31.281196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {}\n\nif TUNE_REGRESSORS == True:\n    for model in models_set:\n        model_name = str(model.__class__).split('.')[-1][:-2]\n        tuned_model, tuner = tune_model( model, n_iter=10, optimize='MAE', choose_better=True, return_train_score=False, return_tuner=True, verbose=True)\n        models[ model_name ] = { 'instance':tuned_model, 'tuner':tuner }\nelse:\n    for model in models_set:\n        model_name = str(model.__class__).split('.')[-1][:-2]\n        models[model_name] = { 'instance':model}","metadata":{"execution":{"iopub.status.busy":"2023-11-09T19:57:52.898602Z","iopub.execute_input":"2023-11-09T19:57:52.899777Z","iopub.status.idle":"2023-11-09T19:57:52.912502Z","shell.execute_reply.started":"2023-11-09T19:57:52.899724Z","shell.execute_reply":"2023-11-09T19:57:52.911251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model_name in models:\n    model = models[model_name]['instance']\n    features = None\n    \n    for method in ['feature_name_','feature_names_in_','feature_names_']:\n        try: \n            features = list(eval(f'model.{method}'))\n            break\n        except: pass\n        \n    if features == None: raise Exception(f'No feature_names_in found for regressor {model_name}') \n    else: print(f\"Features of {model_name} are loaded.\")\n    models[model_name].update({'features':features})\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T19:57:56.961644Z","iopub.execute_input":"2023-11-09T19:57:56.962087Z","iopub.status.idle":"2023-11-09T19:57:56.971067Z","shell.execute_reply.started":"2023-11-09T19:57:56.962053Z","shell.execute_reply":"2023-11-09T19:57:56.969872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_mask( list_of_features:list ):\n    result = [0] * x_train.shape[1]\n    for f in list_of_features:\n        result[ x_train.columns.get_loc(f) ] = 1\n    return result\n\n\nfrom tensorflow.keras.layers import Layer\n\nclass RegressorBlock(Layer):\n    def __init__(self, regressor, **kwargs ):\n        super().__init__(trainable=False, dynamic=False, **kwargs)\n        self.regressor = regressor\n        \n    def build(self, input_shape):\n        super().build(input_shape)\n    \n    def custom_activation(self, x):\n        x_pred = tf.make_ndarray(tf.make_tensor_proto(x))\n        return tf.convert_to_tensor(self.regressor.predict(x_pred), dtype=tf.float32)\n    \n    def call(self, inputs):\n        assert len(inputs.shape) == 2\n        result = tf.py_function(self.custom_activation, [inputs], tf.float32)\n        return tf.reshape(result, shape=(-1,1))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T19:58:01.986959Z","iopub.execute_input":"2023-11-09T19:58:01.988308Z","iopub.status.idle":"2023-11-09T19:58:02.003198Z","shell.execute_reply.started":"2023-11-09T19:58:01.988249Z","shell.execute_reply":"2023-11-09T19:58:02.001663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model_name in models:\n    models[model_name].update({'tensor':tf.constant( get_mask(models[model_name]['features']), dtype=tf.float32)})","metadata":{"execution":{"iopub.status.busy":"2023-11-09T19:58:07.452385Z","iopub.execute_input":"2023-11-09T19:58:07.453343Z","iopub.status.idle":"2023-11-09T19:58:07.549960Z","shell.execute_reply.started":"2023-11-09T19:58:07.453298Z","shell.execute_reply":"2023-11-09T19:58:07.548713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_len = x_train.shape[1] \nmasking_func = lambda param: tf.boolean_mask(param[0],param[1], axis=1)\nconcat_array =[]\n\nl_input = ly.Input(shape=(input_len,),name='input') \n\nfor model_name in models:\n    n_features = len(models[model_name]['features'])\n    l_mask = ly.Lambda(masking_func, output_shape=(None, n_features), name=f\"masking_layer_{ model_name }\")([l_input, models[model_name]['tensor']])\n    \n    l_reg = RegressorBlock( models[model_name]['instance'], name=f\"block_{ model_name }\" )(l_mask) \n    concat_array.append(l_reg)\n\nl_concat = ly.Concatenate(name='concat_outputs')(concat_array)\n\nbalance_layers = [ly.Dense(QTY_REGRESSORS, name='balance_layer_0')(l_concat)]\nfor i in range(QTY_REGRESSORS):\n    balance_layers.append(ly.Dense(QTY_REGRESSORS, name=f'balance_layer_{i+1}')(balance_layers[-1]))\n\nl_output = ly.Dense(1, name='output')(balance_layers[-1])\n\nmodel_0 = Model(inputs=l_input, outputs=l_output)\nplot_model(model_0, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T19:58:27.672288Z","iopub.execute_input":"2023-11-09T19:58:27.672736Z","iopub.status.idle":"2023-11-09T19:58:29.453097Z","shell.execute_reply.started":"2023-11-09T19:58:27.672703Z","shell.execute_reply":"2023-11-09T19:58:29.452264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n\ndef compile_and_fit_model(model, mode='main', batch=1, epochs=100, verbose=1):\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n                      loss=tf.keras.losses.mae, metrics=['mae'])\n    \n    if mode == 'main':\n        history = model.fit(\n            x=tf.constant(x_train), y=tf.constant(y_train),\n            batch_size=batch, epochs=epochs, steps_per_epoch=int(.8*len(x_train)/batch), \n            validation_split=0.2, verbose=verbose,\n            callbacks=[\n                ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1),\n                EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n            ])\n    elif mode =='test':\n        history = model.fit(\n            x=tf.constant(xtrain), y=tf.constant(ytrain),\n            batch_size=batch, epochs=epochs, steps_per_epoch=int(.75*len(xtrain)/batch), \n            validation_data=0.25, verbose=verbose,\n            callbacks=[\n                ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1),\n                EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n            ])\n    else: raise Exception(f'Mode {mode} is not available to our fit process.')\n        \n    pd.DataFrame(history.history).plot()\n    return history\n\ndef evaluate_model(model):\n    evaluate = lambda y_true, y_pred: { 'r2': r2_score(y_true, y_pred), 'mae': mean_absolute_error(y_true, y_pred), 'rmse': mean_squared_error(y_true, y_pred, squared=True) }\n    y_pred = model.predict(tf.constant(xval), verbose=0)\n    result = evaluate(yval.values.reshape(-1,1), y_pred)\n    print(f'\\nResultado = {result}\\n')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T20:01:51.040118Z","iopub.execute_input":"2023-11-09T20:01:51.040590Z","iopub.status.idle":"2023-11-09T20:01:51.053928Z","shell.execute_reply.started":"2023-11-09T20:01:51.040553Z","shell.execute_reply":"2023-11-09T20:01:51.052770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_0.fit(\n    x=tf.constant(xtrain), y=tf.constant(ytrain),\n    batch_size=1, epochs=100, steps_per_epoch=1168, \n    validation_data=0.25, verbose=1,\n    callbacks=[\n        ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1),\n        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-11-09T20:16:33.033246Z","iopub.execute_input":"2023-11-09T20:16:33.033719Z","iopub.status.idle":"2023-11-09T20:17:14.089606Z","shell.execute_reply.started":"2023-11-09T20:16:33.033673Z","shell.execute_reply":"2023-11-09T20:17:14.088061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compile_and_fit_model(model_0, mode=EXEC_MODE, batch=1, epochs=100, verbose=1)\nevaluate_model(model_0)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T20:10:07.093909Z","iopub.execute_input":"2023-11-09T20:10:07.094428Z","iopub.status.idle":"2023-11-09T20:10:30.415321Z","shell.execute_reply.started":"2023-11-09T20:10:07.094384Z","shell.execute_reply":"2023-11-09T20:10:30.412599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}